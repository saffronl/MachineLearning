Precision - from all classes predicted as positive, how many are actually positive

Recall - from all the positive classes, how many were predicted correctly

Accuracy - from all classes (postive & negative), how many were predicted correctly

Confusion Matrix - A confusion matrix is helpful for measuring recall, precision, specificity, and accuracy. The matrix is a 2x2 with true positive, true negative, false positive, and false negative.

Evaluate the accuracy of the model using the testing dataset. Cross validation will provide three values from the number of "k-folds" specified. Cross-Validation has two main steps: splitting the data into subsets (called folds) and rotating the training and validation among them. https://towardsdatascience.com/what-is-cross-validation-60c01f9d9e75

Specificity - the model's ability to predict a true negative

FPR - false positive rate (1-specificity)

Sensitivity - a measure of how well a model can detect positive instances (inverse of specificity)

ROC Curve - recall, specificity, false positive rate, sensitivity

Bias - pull towards outliers

Variance - difference between models when using subsects of the data

Cross Fold - In k-fold cross-validation, you split the input data into k subsets of data (also known as folds). You train an ML model on all but one (k-1) of the subsets, and then evaluate the model on the subset that was not used for training.

















